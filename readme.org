#+TITLE: Edit Imputation
#+AUTHOR: Zhenhua Wang
#+SETUPFILE: ~/.emacs.d/OrgFiles/LatexTemplates/zw-latex-standard.setup
#+OPTIONS: toc:nil
#+BIBLIOGRAPHY: ./reference.bib

* Table of Contents :noexport:TOC:
- [[#automatic-edit-and-imputation][Automatic Edit and Imputation]]
- [[#bayesian-edit-imputation][Bayesian Edit Imputation]]
- [[#complex-survey][Complex Survey]]
- [[#reference][Reference]]

* Automatic Edit and Imputation
- select reported values to change according to some heuristic or loss function
- replace those values with plausible imputations

* Bayesian Edit Imputation
** Multiple Imputation of Missing or Faulty Values Under Linear Constraints [cite:@kim2014multiple]
This paper follows a two-step imputation process. It first models the data using Dirichlet Process Mixtures of Normals with Truncation. Then, it uses a hit-and-run sampler for the imputation.

** Simultaneous Edit-Imputation for Continuous Microdata [cite:@kim2015simultaneous]
In this paper, the author uses a hierarchical model with three levels. It includes a model for the true data with the support on the set of values that satisfy all editing constrain, a model for latent indicators of the variables that are in error, and models (measurement error model) for the reported responses for variables in error.

Specifically, it uses a finite mixture of multivariate normal distributions with a constrained support for true data model, a uniform distribution for error indicator model.

** Bayesian Simultaneous Edit and Imputation for Multivariate Categorical Data [cite:@manrique2017bayesian]
This paper uses the truncated Bayesian nonparametric latent class model as their response model.

**  Simultaneous Edit and Imputation For Household Data with Structural Zeros [cite:@akande2019simultaneous]
This paper uses a nested data Dirichlet process mixture of products of multinomial distributions as the model for the true latent values of the data, truncated to allow only households that satisfy all edit constraints.

** Statistical Disclosure Limitation in the Presence of Edit Rules [cite:@kim2015statistical]
This paper compares edit-after-SDL and edit-preserving SDL. In edit-after-SDL, an agency first applies an SDL method to the collected data. Any post-SDLrecords that violate the constraints are deleted or “repaired”. In edit-preserving SDL, we draw candidate masked values repeatedly until they satisfy all edit rules (e.g. through reject sampling).

** Simultaneous edit-imputation and disclosure limitation for business establishment data [cite:@kim2018simultaneous]
This paper uses a two-stage process. The first stage [cite:@kim2015simultaneous] generates $m$ plausible imputations that satisfy all edit rules. The second stage re-estimate the joint probability model on each of the $m$ plausible datasets and generates $r$ synthetic datasets for each plausible edited dataset.

** Synthetic microdata for establishment surveys under informative sampling [cite:@kim2021synthetic]
This paper is built on top of [cite:@kim2014multiple], and it incorporates pseudo likelihood framework in DP Gaussian mixture model.

* Complex Survey
** Bayesian estimation under informative sampling [cite:@savitsky2016bayesian]

** Fully Bayesian estimation under informative sampling [cite:@leon2019fully]
This paper derives the posterior population distribution corrected by sampling weights

** Bayesian Data Synthesis and Disclosure Risk Quantification: An Application to the Consumer Expenditure Surveys [cite:@hu2018bayesian]
This paper protects the county label of consumer units in CES. They use two models:
1. Dirichlet Process mixtures of products of multinomials
2. nonparametric version of areal models with Dirichlet Process priors (DP-areal), which models counts of county labels of observations sharing similar characteristics.

** Risk-Efficient Bayesian Data Synthesis for Privacy Protection [cite:@hu2022risk]
This paper generates synthetic data through pseudo posterior where records with high identification risk are down-weighted. The identification risk is defined by the probability that the synthetic values for a record are not close to the truth.

** Bayesian pseudo posterior mechanism under asymptotic differential privacy [cite:@savitsky2022bayesian]
This paper extends [cite:@hu2022risk] and shows a connection between pseudo posterior and differential privacy, by constructing risk-related weights that achieves a formal privacy guarantee.

** Private Tabular Survey Data Products through Synthetic Microdata Generation [cite:@hu2022private]
1. Fully Bayes model of observed sample: FBS jointly models sampling weighs and observed samples with a bivariate normal distribution
2. Fully Bayes model of population: FBP uses sampling weights to correct population bias and the outcome variable under the population distribution

* Reference :ignore:
#+CITE_EXPORT: natbib kluwer
#+PRINT_BIBLIOGRAPHY:
